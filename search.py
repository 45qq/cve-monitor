# cd /root/sh/git/ && nohup python3 /root/sh/git/git.py &
# coding:UTF-8

import json
import time
import sys
import requests
import requests.packages.urllib3 as urllib3

time_sleep = 60  # 每隔 20 秒爬取一次

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) " +
                  "Chrome / 70.0.3538.25 Safari / 537.36 Core / 1.70.3741.400 QQBrowser / 10.5.3863.400"
}


def crawling(key):
    page = 1
    index = 0
    while True:
        # 将提取出来的数据中的 nan 转化为 None
        urllib3.disable_warnings()
        try:
            response = requests.get(
                url="https://api.github.com/search/repositories?q=%s&ssort=updated&&order=desc&page=%d" % (
                    key, page),
                headers=headers, verify=False)
        except Exception as e:
            print("请检查网络连接！")
            print(e)
            sys.exit(0)

        data_list: list = json.loads(response.text)["items"]

        for i in data_list:
            name = i['name']
            url = i['html_url']
            description = i['description']

            index += 1
            print("%d.当前推送为：%s\n链接：%s\n描述：%s\n" % (index, name, url, description), end='')

            time.sleep(1)
            page += 1
            print()

            if index % 10 == 0:
                c = input("按回车继续，输入任意字符退出：")
                if c != '':
                    sys.exit(0)


def show_help():
    print("usage: main.py <搜索的关键词>")


if __name__ == '__main__':
    if len(sys.argv) > 1:
        if '-h' in sys.argv or '--help' in sys.argv:
            show_help()
            sys.exit(0)

        crawling(sys.argv[1])
    else:
        show_help()
